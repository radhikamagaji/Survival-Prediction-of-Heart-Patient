---
title: "HeartProj_DecisionTrees"
author: "Radhika"
date: "5/28/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}
library(ggplot2)
library(ISLR2)
library(randomForest)
library(tree)
library(dplyr)
library(gbm)  #xgboost
library(JOUSBoost) #adaboost
library(randomForest)
library(boot)
library(xgboost)
library(tidyverse)
library(caret)
library(adabag)
library(e1071)
```

```{r}
heart = read.csv("E:\\Radhika\\SU_MSDS\\Spring22Quarter\\DATA5332_StatML2\\DATA5322_Assignments\\DATA_5332_Project\\heart_failure_clinical_records_dataset.csv")
```

```{r}
heart
```

```{r}
#converting to factor variables

heart$DEATH_EVENT <- as.factor(heart$DEATH_EVENT)
heart$anaemia <- as.factor(heart$anaemia)
heart$diabetes <- as.factor(heart$diabetes)
heart$high_blood_pressure  <- as.factor(heart$high_blood_pressure)
heart$sex  <- as.factor(heart$sex)
heart$smoking  <- as.factor(heart$smoking)
#heart$sex  <- as.factor(heart$sex)
```
```{r}
str(heart)
```
```{r}
unique(heart$high_blood_pressure)
```

```{r}
#Split to train and test 

train <- sample(nrow(heart) * 0.7)
train_df  <- heart[train, ]
test_df <- heart[-train, ]
```
```{r}
dim(train_df)
dim(test_df)
```

 


```{r}
#Model with all predictors
tree.heart <- tree(DEATH_EVENT ~ .-time, data = train_df, control = tree.control(nrow(train_df), mindev = 0, minsize = 3))
summary(tree.heart)
```
```{r}
cv.heart <- cv.tree(tree.heart,FUN = prune.misclass)
plot(cv.heart$size, cv.heart$dev, type = "b" , xlab= "size" , ylab ="deviance")  
plot(cv.heart$k, cv.heart$dev, type = "b" , xlab= "K" , ylab ="deviance")
``` 

Pruning the tree
```{r}
  prune.heart <- prune.tree(tree.heart, best = 9)
  plot(prune.heart)
  text(prune.heart, pretty = 0)
```

```{r}
yhat <- predict(prune.heart, newdata = test_df, type="class")

table(yhat, test_df$DEATH_EVENT)
```

```{r}
mean(yhat == test_df$DEATH_EVENT)
```
Randon Forest
```{r}
npredictors = 13
rf_bag<- randomForest(DEATH_EVENT ~ .-time, 
                           data=train_df,
                           ntree = 500,
                           mtry=(npredictors-2), 
                           importance=TRUE)

rf_sqrt_n <- randomForest(DEATH_EVENT ~ .-time, 
                           data=train_df,
                           ntree = 500,
                           mtry=sqrt(npredictors-2), 
                           importance=TRUE)

rf_half_n <- randomForest(DEATH_EVENT ~ .-time, 
                           data=train_df,
                           ntree = 500,
                           mtry=(npredictors-2)/2, 
                           importance=TRUE)

```
```{r}


predicted_event<-predict(rf_bag, newdata = test_df)
plot(predicted_event , test_df$DEATH_EVENT)
table(predicted_event, test_df$DEATH_EVENT)
cat("error rate : ", 1- mean(predicted_event == test_df$DEATH_EVENT))

test_df["RF_bag"] = yhat
```

```{r}


predicted_event<-predict(rf_half_n, newdata = test_df)
plot(predicted_event , test_df$DEATH_EVENT)
table(predicted_event, test_df$DEATH_EVENT)
cat("error rate : ", 1- mean(predicted_event == test_df$DEATH_EVENT))

test_df["rf_half_n"] = yhat
```
```{r}
predicted_event<-predict(rf_sqrt_n, newdata = test_df)
plot(predicted_event , test_df$DEATH_EVENT)
table(predicted_event, test_df$DEATH_EVENT)
cat("error rate : ", 1- mean(predicted_event == test_df$DEATH_EVENT))

test_df["rf_sqrt_n"] = yhat
```
```{r}
par(mfrow = c(1, 3))
varImpPlot(rf_bag,n.var = 5,type =1,adjust_ylab=1.5 , main = "Bagging" )
varImpPlot(rf_sqrt_n,n.var = 5,type =1,adjust_ylab=1.5 , main ="Squared root of n")
varImpPlot(rf_half_n,n.var = 5,type =1,adjust_ylab=1.5 , main = "Half of n")
```

```{r}
event_error <- data.frame(
  Trees=1:rf_bag$ntree,
  Error=c(rf_bag$err.rate[,"OOB"],rf_sqrt_n$err.rate[,"OOB"], rf_half_n$err.rate[,"OOB"]),
  Type=rep(c("Bag", "RF, m=sqrt(p)", "RF, m=p/2"), each=rf_bag$ntree)
)
```


```{r}
ggplot(data=event_error, aes(x=Trees, y=Error)) +  geom_line(aes(color=Type)) + ggtitle("Error vs Number of Trees")
```
SVM
```{r}
#Split to train and test 
set.seed(123)
trainindex <- sample(nrow(heart) * 0.6)
train <- heart[trainindex, ]
test <- heart[-trainindex, ]
```

```{r}
dim(train)
dim(test)
```

```{r}
#kernel=Linear
 
svmfit.linear <- svm(DEATH_EVENT ~ ejection_fraction + serum_creatinine,
              data = train_df ,
              kernel = "linear",
              cost = 1,
              scale = FALSE)
```

```{r}
predict.linear <- predict(svmfit.linear, test_df )
mean(predict.linear==test_df$DEATH_EVENT)

plot(svmfit.linear, data = test_df , ejection_fraction~serum_creatinine)
```


```{r}
svmfit.linear.tune <- tune(svm, DEATH_EVENT ~ ejection_fraction + serum_creatinine,
              data = train_df ,
              kernel = "linear",
              cost = c(0.1, 1, 10, 100),
              scale = FALSE)

summary.tune.linear <- summary(svmfit.linear.tune)
print(summary.tune.linear$best.model)
```


```{r}
predict.linear.tune <- predict(svmfit.linear.tune$best.model, test_df)
mean(predict.linear.tune == test_df$DEATH_EVENT)

table(predict.linear.tune,test_df$DEATH_EVENT)

plot(svmfit.linear.tune$best.model, data = test_df , ejection_fraction~serum_creatinine)
```
```{r}
svmfit.polynomial <- svm(DEATH_EVENT ~ejection_fraction+serum_creatinine ,
              data = train_df ,
              kernel = "polynomial",
              cost = 1,
              degree = 3,
              scale = FALSE)

pred = predict(svmfit.linear.tune$best.model, test_df)
mean(pred == test_df$DEATH_EVENT)

table(pred,test_df$DEATH_EVENT)

plot(svmfit.polynomial, data = test_df , ejection_fraction~serum_creatinine)
```
```{r}
cost_power_range <- seq(-2, 2, 0.5)
cost_range <- 10^cost_power_range
gamma_power_range <- -2:2
gamma_range <- 10^gamma_power_range
number <- 10
repeats <- 3

cv_matrix <- matrix(nrow = length(cost_power_range)*length(gamma_power_range), ncol = repeats)

set.seed(666)
for (i in 1:repeats) {
  svm_radial_tune <- tune(svm, as.factor(DEATH_EVENT) ~ ejection_fraction+serum_creatinine, data = train_df, kernel = "radial", scale = TRUE, ranges = list(gamma = gamma_range, cost = cost_range), tunecontrol = tune.control(sampling = "cross", cross = number))
  cv_matrix[ ,i] <- svm_radial_tune$performances$error
}

svm_radial_df <- cbind(svm_radial_tune$performances[ ,c("gamma", "cost")], CV_error = rowMeans(cv_matrix)) %>%
  mutate(min_CV_error = as.numeric(CV_error == min(CV_error)))
```


```{r}
svm_radial_tune$best.parameters

ggplot(svm_radial_df, aes(x = cost, y = CV_error, col = factor(gamma))) + 
  geom_line() + 
  geom_point(aes(shape = factor(min_CV_error)), show.legend = F, size = 3) + 
  scale_shape_manual(values = c(20, 19)) +
  scale_x_continuous(trans = 'log10', breaks = cost_range, minor_breaks = NULL, labels = paste0("10^", cost_power_range)) + 
  scale_y_continuous(labels = scales::percent_format(accuracy=1L)) +
  scale_color_discrete(labels = paste0("10^", gamma_power_range)) +
  coord_cartesian(ylim = c(.2, 0.5)) +
  theme(axis.text.x = ggtext::element_markdown(), 
        legend.text = ggtext::element_markdown(), 
        legend.position = "bottom") +
  labs(title = "Binary classification - SVM (Radial Kernel)", 
       subtitle = "Selecting cost & gamma parameters using cross-validation",
       x = "Cost", 
       y = "CV Error", 
       col = "Gamma")
```
```{r}
svmfit.radial <- svm(DEATH_EVENT ~ejection_fraction+serum_creatinine ,
              data = train_df ,
              kernel = "radial",
              cost = .316,
              gamma = 1,
              scale = FALSE)

pred = predict(svmfit.radial, test_df)
mean(pred == test_df$DEATH_EVENT)

table(pred,test_df$DEATH_EVENT)

plot(svmfit.radial, data = test_df , ejection_fraction~serum_creatinine)
```

```{r}
power_range <- seq(1, 7, 0.5)
cost_range <- 10^power_range
degree_range <- 2:7
number <- 10
repeats <- 2

cv_matrix <- matrix(nrow = length(cost_range)*length(degree_range), ncol = repeats)

set.seed(151)
for (i in 1:repeats) {
  svm_poly_tune <- tune(svm, DEATH_EVENT ~ejection_fraction+serum_creatinine, data = train_df, kernel = "polynomial", scale = TRUE, ranges = list(degree = degree_range, cost = cost_range), tunecontrol = tune.control(sampling = "cross", cross = number))
  cv_matrix[ ,i] <- svm_poly_tune$performances$error
}

svm_poly_df <- cbind(svm_poly_tune$performances[ ,c("degree", "cost")], CV_error = rowMeans(cv_matrix)) %>%
  mutate(min_CV_error = as.numeric(CV_error == min(CV_error)))

```

```{r}
ggplot(svm_poly_df, aes(x = cost, y = CV_error, col = factor(degree))) + 
  geom_line() + 
  geom_point(aes(shape = factor(min_CV_error)), show.legend = F, size = 3) + 
  scale_shape_manual(values = c(20, 19)) +
  scale_x_continuous(trans = 'log10', breaks = cost_range, minor_breaks = NULL, labels = paste0("10^", power_range)) + 
  scale_y_continuous(labels = scales::percent_format(accuracy = 1L)) +
 # coord_cartesian(ylim = c(0, 0.8)) +
  theme(axis.text.x = ggtext::element_markdown(), 
        legend.position = "bottom") +
  labs(title = "Multiclass SVM (Polynomial Kernel)", 
       subtitle = "Selecting cost & degree parameters using cross-validation",
       x = "Cost", 
       y = "CV Error", 
       col = "Degree")
```
